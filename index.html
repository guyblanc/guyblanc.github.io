<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<<meta name="google-site-verification" content="NkmRoQoNesV8hiktDI05kbkW1RY6Ug9Z25DpcEDipx4" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Guy Blanc</title>
</head>
<body>
<div id="layout-content">
<h3></h3>
<h1>Guy Blanc</h1>
<p>Contact: gblanc (at) stanford.edu</p>
<h2></h2>
<table class="imgtable"><tr><td>
<img src="GuyHeadShot.jpg" alt="guy_head_shot" width="200px" />&nbsp;</td>
<td align="left"><p>I'm Guy, a PhD student in the <a href="https://theory.stanford.edu/main/index.shtml">Stanford CS theory group</a>. I am extremely fortunate to be advised by <a href="http://theory.stanford.edu/~liyang/">Li-Yang Tan</a>. My research is generously supported by a <a href="https://www.janestreet.com/join-jane-street/programs-and-events/grf-profiles-2024/">Jane Street Graduate Research Fellowship</a>.</p>
<p>In my free time, I enjoy <a href="hiking.jpg">hiking</a>, <a href="dancing.jpg">dancing</a>, and <a href="soccer.jpg">playing/watching sports</a>.</p>
</td></tr></table>
<h2>Selected publications</h2>
<dl>
<dt><a href="https://arxiv.org/abs/2410.13548">Adaptive and oblivious statistical adversaries are equivalent</a></dt>
<dd><p><span  class="myname">Guy Blanc</span> and Gregory Valiant<br />
STOC 2025<br />
Invited to STOC 2025 special issue</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2409.11597">The sample complexity of smooth boosting and the tightness of the hardcore theorem</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Alexandre Hayderi, Caleb Koch, and Li-Yang Tan<br />
FOCS 2024<br />
Invited to FOCS 2024 special issue</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2302.08661">Subsampling Suffices for Adaptive Data Analysis</a></dt>
<dd><p><span  class="myname">Guy Blanc</span><br />
STOC 2023 <br />
Best student paper at STOC 2023<br />
Invited to STOC 2023 special issue<br />
Journal of the ACM, 2025</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2109.00637">Properly learning decision trees in almost polynomial time</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Jane Lange, Mingda Qiao, and Li-Yang Tan<br />
FOCS 2021<br />
Invited to FOCS 2021 special issue<br />
Journal of the ACM, 2022</p></dd>
</dl>
<h2>All publications</h2>
<p>In my field, we generally order authors alphabetically by last name.</p>
<dl>
<dt><a href="noArxivYet.html">Is nasty noise actually harder than malicious noise?</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Yizhi Huang, Tal Malkin, and Rocco Servedio<br />
SODA 2026, to appear</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2507.13222">Computational-Statistical Tradeoffs from NP-hardness</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Caleb Koch, Carmen Strassle, and Li-Yang Tan<br />
FOCS 2025, to appear</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2508.02637">Instance-Optimal Uniformity Testing and Tracking</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Cl√©ment Canonne, and Erik Waingarten<br />
FOCS 2025, to appear</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2410.13548">Adaptive and oblivious statistical adversaries are equivalent</a></dt>
<dd><p><span  class="myname">Guy Blanc</span> and Gregory Valiant<br />
STOC 2025<br />
<b>Invited to STOC 2025 special issue</b></p></dd>
</dl>
<dl>
<dt><a href="https://www.arxiv.org/abs/2506.16651">A Distributional-Lifting Theorem for PAC Learning</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Jane Lange, Carmen Strassle, and Li-Yang Tan<br />
COLT 2025</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2409.11597">The sample complexity of smooth boosting and the tightness of the hardcore theorem</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Alexandre Hayderi, Caleb Koch, and Li-Yang Tan<br />
FOCS 2024<br />
<b>Invited to FOCS 2024 special issue</b></p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2405.16340">A strong direct sum theorem for distributional query complexity</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Caleb Koch, Carmen Strassle, and Li-Yang Tan<br />
CCC 2024<br />
<b>Invited to CCC 2024 special issue</b></p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2307.04039">A Strong Composition Theorem for Junta Complexity and the Boosting of Property Testers</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Caleb Koch, Carmen Strassle, and Li-Yang Tan<br />
FOCS 2023</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2310.01551">Harnessing the Power of Choices in Decision Tree Learning</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Jane Lange, Chirag Pabbaraju, Colin Sullivan, Li-Yang Tan, and Mo Tiwari<br />
NeurIPS 2023</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2302.08661">Subsampling Suffices for Adaptive Data Analysis</a></dt>
<dd><p><span  class="myname">Guy Blanc</span><br />
STOC 2023 <br />
<b>Best student paper at STOC 2023</b><br />
<b>Invited to STOC 2023 special issue</b><br />
<b>Journal of the ACM, 2025</b></p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2303.16208">Lifting uniform learners via distributional decomposition</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Jane Lange, Ali Malik, and Li-Yang Tan<br />
STOC 2023 </p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2209.03112">Multitask Learning via Shared Features: Algorithms and Hardness</a></dt>
<dd><p>Konstantina Bairaktari, <span  class="myname">Guy Blanc</span>, Li-Yang Tan, Jonathan Ullman, Lydia Zakynthinou<br />
COLT 2023</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2211.02257">Certification with an NP Oracle</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Caleb Koch, Jane Lange, Carmen Strassle, and Li-Yang Tan<br />
ITCS 2023</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2207.07072">A query-optimal algorithm for finding counterfactuals</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Caleb Koch, Jane Lange, and Li-Yang Tan<br />
ICML 2022</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2206.08899">Popular decision tree algorithms are provably noise tolerant</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Jane Lange, Ali Malik, and Li-Yang Tan<br />
ICML 2022</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2111.10352">On the power of adaptivity in statistical adversaries</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Jane Lange, Ali Malik, and Li-Yang Tan<br />
COLT 2022</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2206.14431">Open problem: Properly learning decision trees in polynomial time?</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Jane Lange, Mingda Qiao, and Li-Yang Tan<br />
COLT 2022<br />
Open problems track</p></dd>
</dl>
<dl>
<dt><a href="https://eccc.weizmann.ac.il/report/2022/027/">New Near-Linear Time Decodable Codes Closer to the GV Bound</a></dt>
<dd><p><span  class="myname">Guy Blanc</span> and Dean Doron<br />
CCC 2022</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2012.08735">Reconstructing decision trees</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Jane Lange, and Li-Yang Tan<br />
ICALP 2022</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2201.07736">The query complexity of certification</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Caleb Koch, Jane Lange, and Li-Yang Tan<br />
STOC 2022</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2111.01576">Provably efficient, succinct, and precise explanations</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Jane Lange, and Li-Yang Tan<br />
NeurIPS 2021</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2106.05579">Multiway online correlated selection</a></dt>
<dd><p><span  class="myname">Guy Blanc</span> and Moses Charikar<br />
FOCS 2021</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2109.00637">Properly learning decision trees in almost polynomial time</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Jane Lange, Mingda Qiao, and Li-Yang Tan<br />
FOCS 2021<br />
<b>Invited to FOCS 2021 special issue</b><br />
<b>Journal of the ACM, 2022</b></p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2107.00819">Decision tree heuristics can fail, even in the smoothed setting</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Jane Lange, Mingda Qiao, and Li-Yang Tan<br />
RANDOM 2021</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2105.03594">Learning stochastic decision trees</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Jane Lange, and Li-Yang Tan<br />
ICALP 2021</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2010.11381">Query strategies for priced information, revisited</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Jane Lange, and Li-Yang Tan<br />
SODA 2021</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2010.08633">Universal guarantees for decision tree induction via a higher-order splitting criterion</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Neha Gupta, Jane Lange, and Li-Yang Tan<br />
NeurIPS 2020</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2011.01584">Estimating decision tree learnability with polylogarithmic sample complexity</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Neha Gupta, Jane Lange, and Li-Yang Tan<br />
NeurIPS 2020</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/1904.09080">Implicit regularization for deep neural networks driven by an Ornstein-Uhlenbeck like process</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Neha Gupta, Gregory Valiant, and Paul Valiant<br />
COLT 2020</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2006.00743">Provable guarantees for decision tree induction: the agnostic setting</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Jane Lange, and Li-Yang Tan<br />
ICML 2020</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/1911.07375">Top-down induction of decision trees: rigorous guarantees and inherent limitations</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Jane Lange, and Li-Yang Tan<br />
ITCS 2020</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/1712.00527">Adaptive sampled softmax with kernel based sampling</a></dt>
<dd><p><span  class="myname">Guy Blanc</span>, Steffen Rendle<br />
ICML 2018</p></dd>
</dl>
<div id="footer">
<div id="footer-text">
Page generated 2025-10-13 21:29:47 EDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</div>
</body>
</html>
